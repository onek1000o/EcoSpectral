import os
import warnings
import numpy as np
from spectral import *
import sys

# Importaciones para CNN
import torch
import tensorflow as tf
from tensorflow import keras
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv1D, Flatten, Dropout, MaxPooling1D
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.utils import to_categorical

# Configuraci√≥n de advertencias
warnings.filterwarnings('ignore', category=RuntimeWarning)

def detectar_so():
    system = sys.platform
    if system == 'linux':
        print(f"üêß Sistema operativo Linux")
    elif system == 'win32' or system == 'cygwin' or system == 'msys' or system == 'win64' or system == 'x64':
        print(f"ü™ü Sistema operativo Windows")
    elif system == 'darwin' or system == 'macos' or system == 'os2' or system == 'os2emx' or system == 'riscos' or system == 'atheos':
        print(f"üçéSistema operativo MacOS")

# ? Detecta y configura dispositivos GPU disponibles de cualquier tipo
def detectar_y_configurar_gpu():
    # * Returns:
    # * str: Dispositivo a usar ('GPU' o 'CPU')

    # Verificar GPUs disponibles usando TensorFlow
    gpus_tf = tf.config.list_physical_devices('GPU')
    gpu_available_tf = len(gpus_tf) > 0

    # Verificar GPU disponible usando PyTorch
    gpu_available_tp = torch.cuda.is_available()

    if gpu_available_tf or gpu_available_tp:

        try:
            gpu_tipo = 'NVIDIA' if gpu_available_tf else 'AMD/Metal/otros'

            if gpu_available_tf:
                gpu_name = tf.test.gpu_device_name()
            else:
                gpu_name = 'N/A'

            try:
                # Configurar memoria de crecimiento para evitar problemas de OOM
                for gpu in gpus_tf:
                    tf.config.experimental.set_memory_growth(gpu, True)
                logical_gpus = tf.config.list_logical_devices('GPU')
                print(f"{len(gpus_tf)} GPU(s) f√≠sica(s), {len(logical_gpus)} GPU(s) l√≥gica(s)")
                return 'GPU'
            except RuntimeError as e:
                print(f"Error configurando GPU: {e}")

            # Seleccionar la primera GPU disponible
            logical_gpus = tf.config.list_logical_devices('GPU')
            print(f"üöÄ GPU detectada: {gpu_tipo} (Tipo: {gpu_name})")

            # Configurar para usar la GPU
            tf.config.set_visible_devices(gpus_tf[0], 'GPU')
            return 'GPU'

        except RuntimeError as e:
            print(f"‚ö†Ô∏è Error configurando GPU: {e}")
            print("üîÅ Intentando configuraci√≥n alternativa...")

            # Intentar configuraci√≥n alternativa para GPUs no NVIDIA
            try:
                tf.config.set_visible_devices(gpus_tf[0], 'GPU')
                print(f"‚úÖ Configuraci√≥n alternativa exitosa para GPU: {gpus_tf[0].name}")
                return 'GPU'
            except Exception as alt_e:
                print(f"‚ö†Ô∏è Error en configuraci√≥n alternativa: {alt_e}")
                print("üîÑ Usando CPU como respaldo.")
                return 'CPU'
    else:
        print("üñ•Ô∏è No se detectaron GPUs disponibles. Usando CPU.")
        return 'CPU'

def preparar_datos_para_dispositivo(dispositivo):
    """
    Prepara los datos para el dispositivo seleccionado.

    Args:
        dispositivo (str): 'GPU' o 'CPU'

    Returns:
        Configuraci√≥n espec√≠fica para el dispositivo
    """
    if dispositivo == 'GPU':
        # Configuraci√≥n optimizada para cualquier GPU
        try:
            # Configuraci√≥n para NVIDIA CUDA
            config = tf.compat.v1.ConfigProto()
            config.gpu_options.allow_growth = True
            config.gpu_options.per_process_gpu_memory_fraction = 0.9  # Usar hasta 90% de la memoria

            # Configuraci√≥n para AMD/Metal/otros
            try:
                tf.config.optimizer.set_jit(True)  # Habilitar XLA para cualquier GPU
                tf.config.threading.set_inter_op_parallelism_threads(4)
                tf.config.threading.set_intra_op_parallelism_threads(4)
            except:
                pass

            return tf.keras.backend.set_session(tf.compat.v1.Session(config=config))
        except:
            # Configuraci√≥n gen√©rica si falla la espec√≠fica
            return None
    else:
        # Configuraciones optimizadas para CPU
        tf.config.threading.set_inter_op_parallelism_threads(8)
        tf.config.threading.set_intra_op_parallelism_threads(8)
        return None

# ? Prepara los datos para la CNN
def preparar_datos_cnn(arr_norm, pix_prom_defo, pix_prom_veg):
    print("\n‚è≥ Preparando datos para CNN (versi√≥n vectorizada)...")

    # Obtener dimensiones
    size_img_x, size_img_y, num_bandas = arr_norm.shape

    # Reshape para procesamiento vectorizado
    pixels = arr_norm.reshape(-1, num_bandas)
    mask = np.any(pixels != 0, axis=1)
    pixels = pixels[mask]

    # Calcular distancias vectorizadas
    dist_defo = np.linalg.norm(pixels - pix_prom_defo, axis=1)
    dist_veg = np.linalg.norm(pixels - pix_prom_veg, axis=1)

    # Calcular probabilidades
    total_dist = dist_defo + dist_veg
    prob_defo = np.divide(dist_defo, total_dist, out=np.full_like(dist_defo, 0.5), where=total_dist != 0)
    prob_veg = np.divide(dist_veg, total_dist, out=np.full_like(dist_veg, 0.5), where=total_dist != 0)

    # Asignar etiquetas
    y = np.select(
        [prob_defo < 0.3, prob_veg < 0.3],
        [0, 2],
        default=1
    )

    # Codificar etiquetas
    y = to_categorical(y)

    print(f"üü¢ Datos preparados: {pixels.shape[0]} muestras, {num_bandas} bandas")
    return pixels, y

# ? Entrena el modelo CNN
def entrenar_modelo_cnn(model, X_train, y_train, X_val, y_val, epochs=10, batch_size=8):
    # * Args:
    # * model: Modelo CNN a entrenar
    # * X_train, y_train: Datos de entrenamiento
    # * X_val, y_val: Datos de validaci√≥n
    # * epochs: N√∫mero de √©pocas de entrenamiento
    # * batch_size: Tama√±o del lote
    # *
    # * Returns:
    # * model: Modelo entrenado
    # * history: Historial de entrenamiento

    print("\n‚è≥ Entrenando modelo CNN...")

    # Callbacks para mejorar el entrenamiento
    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.0001)

    history = model.fit(
        X_train, y_train,
        validation_data=(X_val, y_val),
        epochs=epochs,
        batch_size=batch_size,
        callbacks=[early_stopping, reduce_lr],
        verbose=1
    )

    print("üü¢ Modelo CNN entrenado")
    return model, history

# ? Guarda el modelo CNN entrenado en formato HDF5 (.h5)
def guardar_modelo_cnn(modelo, ruta_modelo):
    # * Guarda un modelo CNN
    # * Args:
    # * modelo: Modelo de Keras a guardar
    # * ruta_modelo: Ruta completa donde se guardar√° el modelo
    # *
    # * Returns:
    # * bool: True si se guard√≥ correctamente, False si hubo error

    print(f"\n‚è≥ Guardando modelo CNN en {ruta_modelo}...")

    try:
        # Crear directorio si no existe
        directorio = os.path.dirname(ruta_modelo)
        if not os.path.exists(directorio):
            os.makedirs(directorio)
            print(f"üü¢ Directorio creado: {directorio}")

        # Guardar el modelo
        modelo.save(ruta_modelo)
        print("üü¢ Modelo CNN guardado correctamente")
        return True
    except Exception as e:
        print(f"‚ùå Error al guardar el modelo: {str(e)}")
        return False

# ? Entrena el modelo CNN y lo guarda
def entrenar_y_guardar_modelo_cnn(model, X_train, y_train, X_val, y_val, ruta_guardado, epochs=20, batch_size=32):
    # * Args:
    # * model: Modelo CNN a entrenar
    # * X_train, y_train: Datos de entrenamiento
    # * X_val, y_val: Datos de validaci√≥n
    # * ruta_guardado: Ruta donde se guardar√° el modelo
    # * epochs: N√∫mero de √©pocas de entrenamiento
    # * batch_size: Tama√±o del lote
    # *
    # * Returns:
    # * model: Modelo entrenado
    # * history: Historial de entrenamiento
    # * bool: True si se guard√≥ correctamente

    print("\n‚è≥ Entrenando y guardando modelo CNN...")

    # Entrenar el modelo
    model, history = entrenar_modelo_cnn(model, X_train, y_train, X_val, y_val, epochs, batch_size)

    # Guardar el modelo
    guardado_exitoso = guardar_modelo_cnn(model, ruta_guardado)

    return model, history, guardado_exitoso

# ? Carga o crea un modelo CNN seg√∫n disponibilidad
def cargar_o_crear_modelo(ruta_modelo, input_shape=None, num_classes=None, datos_entrenamiento=None):

    # * Args:
    # * ruta_modelo: Ruta donde buscar/guardar el modelo
    # * input_shape: Forma de entrada para crear nuevo modelo (opcional si hay que crearlo)
    # * num_classes: N√∫mero de clases para crear nuevo modelo (opcional si hay que crearlo)
    # * datos_entrenamiento: Tupla (X, y) para entrenamiento si hay que crear modelo (opcional)
    # *
    # * Returns:
    # * model: Modelo cargado o nuevo modelo entrenado
    # * history: Historial de entrenamiento (None si se carg√≥ modelo existente)

    # ? Crea un modelo CNN adaptable
    def crear_modelo_cnn(input_shape, num_classes=3, dispositivo='CPU'):
        # * Args:
        # * input_shape: Forma de los datos de entrada (n√∫mero de bandas)
        # * num_classes: N√∫mero de clases de salida
        # *
        # * Returns:
        # * model: Modelo CNN compilado

        print("\n‚è≥ Creando modelo CNN...")

        model = Sequential()

        # Capa convolucional 1D para manejar las bandas espectrales
        model.add(Conv1D(filters=64, kernel_size=5, activation='relu',
                         input_shape=input_shape, padding='same'))
        model.add(MaxPooling1D(pool_size=2))
        model.add(Dropout(0.3))

        # Segunda capa convolucional
        model.add(Conv1D(filters=128, kernel_size=3, activation='relu', padding='same'))
        model.add(MaxPooling1D(pool_size=2))
        model.add(Dropout(0.3))

        # Tercera capa convolucional
        model.add(Conv1D(filters=256, kernel_size=3, activation='relu', padding='same'))
        model.add(MaxPooling1D(pool_size=2))
        model.add(Dropout(0.3))

        # Aplanar y capas densas
        model.add(Flatten())
        model.add(Dense(128, activation='relu'))
        model.add(Dropout(0.5))
        model.add(Dense(num_classes, activation='softmax'))

        # Compilar el modelo
        model.compile(optimizer='adam',
                      loss='categorical_crossentropy',
                      metrics=['accuracy'])

        print("üü¢ Modelo CNN creado y compilado")
        return model

    try:
        #? Intentar cargar modelo existente
        if os.path.exists(ruta_modelo):
            print(f"üü¢ Cargando modelo CNN existente de {ruta_modelo}")
            model = tf.keras.models.load_model(ruta_modelo)
            return model, None
    except Exception as e:
        print(f"‚ö†Ô∏è Error al cargar modelo existente: {str(e)}")

    #? Si no se pudo cargar, crear uno nuevo
    print("‚ö†Ô∏è No se encontr√≥ modelo preentrenado. Creando nuevo modelo...")

    if input_shape is None or num_classes is None or datos_entrenamiento is None:
        raise ValueError("Se necesitan input_shape, num_classes y datos_entrenamiento para crear nuevo modelo")

    X, y = datos_entrenamiento
    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)
    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)
    X_val = X_val.reshape(X_val.shape[0], X_val.shape[1], 1)

    model = crear_modelo_cnn(input_shape, num_classes)
    model, history, _ = entrenar_y_guardar_modelo_cnn(
        model, X_train, y_train, X_val, y_val, ruta_modelo
    )

    return model, history


def main():
    # Configurar dispositivo primero
    detectar_so()
    dispositivo = detectar_y_configurar_gpu()
    preparar_datos_para_dispositivo(dispositivo)

    # * Buscar archivos de referencia
    print("\n‚è≥ Buscando archivos de firmas espectrales de referencia...")
    archivos_existen = False
    ruta_base = os.getcwd()

    # * Buscar pixeles promedio .npy / .h5
    posibles_ubicaciones = [
        os.path.join(ruta_base, "database", "fsp"),
        os.path.join(os.path.dirname(ruta_base), "src", "database", "fsp"),
        os.path.join(os.path.dirname(ruta_base), "src", "database", "cnnm")
    ]

    for base_dir_img in posibles_ubicaciones:
        try:
            base_dir_img = os.path.abspath(base_dir_img)
            ruta_veg = "/home/carlos-amaranto/Escritorio/Workspace/project.ecospectral.edu.udc/src/database/fsp/fsp_veg.npy"
            ruta_defo = "/home/carlos-amaranto/Escritorio/Workspace/project.ecospectral.edu.udc/src/database/fsp/fsp_defo.npy"
            ruta_refo = "/home/carlos-amaranto/Escritorio/Workspace/project.ecospectral.edu.udc/src/database/fsp/fsp_refo.npy"
            ruta_cnn_modelo = "src/database/cnnm/cnnm.h5"

            if all(os.path.exists(ruta) for ruta in [ruta_veg, ruta_defo, ruta_refo]):
                print(f"üü¢ Archivos de firmas espectrales encontrados en: {base_dir_img}")
                archivos_existen = True
                break
        except Exception:
            continue

    if not archivos_existen:
        print("\n‚ùå ERROR: No se encontraron los archivos de p√≠xeles de referencia.")
        print("Por favor, verifique que existan los siguientes archivos:")
        print("- fsp_veg.npy (vegetaci√≥n)")
        print("- fsp_defo.npy (deforestaci√≥n)")
        print("- fsp_refo.npy (reforestables)")
        return

    # * Cargar firmas espectrales desde archivos .npy
    try:
        pix_prom_veg = np.load(ruta_veg)
        pix_prom_defo = np.load(ruta_defo)
        pix_prom_refo = np.load(ruta_refo)
        print("üü¢ Firmas espectrales cargadas correctamente")
    except Exception as e:
        print(f"‚ùå Error al cargar firmas espectrales: {str(e)}")
        return

    while True:
        # * Cargar imagen
        print("\n‚è≥ Seleccionando imagen hiperespectral...")
        ruta_imagen = "/home/carlos-amaranto/Escritorio/Workspace/project.ecospectral.edu.udc/src/database/img/cartagena_test.hdr"

        # * Si se seleccion√≥ un .hdr, buscamos el .img correspondiente
        ruta_img = None
        if ruta_imagen.lower().endswith('.hdr'):
            ruta_img = ruta_imagen[:-4] + '.img'  # Reemplaza .hdr por .img
            if os.path.exists(ruta_img):
                print(f"üü¢ Archivo .img encontrado: {ruta_img}")
            else:
                print(f"‚ùå No se encontr√≥ el archivo .img correspondiente a {ruta_imagen}")

        if not ruta_imagen and ruta_img:
            return  # Salir si no se selecciona imagen
        print(f"üü¢ Imagen seleccionada en la ruta {ruta_imagen}")

        # * Preprocesar imagen
        # Cargamos la imagen usando spectral
        img = open_image(ruta_imagen)
        arr = np.asarray(img.load())

        # Normalizaci√≥n por banda
        max_val = np.max(arr)
        min_val = np.min(arr)
        arr_norm = (arr - min_val) / (max_val - min_val)

        print(f"üü¢ Preprocesamiento completado: {arr.shape[0]}x{arr.shape[1]} p√≠xeles, {arr.shape[2]} bandas")

        # * Cargar o crear modelo CNN si es necesario
        ruta_cnn_modelo = os.path.join(os.path.dirname(ruta_base), "src", "database", "cnnm", "cnnm.h5")

        try:
            if (dispositivo == 'GPU'):
                with tf.device('/device:GPU:0'):
                    print("üü¢ GPU seleccionada")
                    # Preparar datos para CNN
                    X, y = preparar_datos_cnn(arr_norm, pix_prom_defo, pix_prom_veg)
                    input_shape = (X.shape[1], 1)
                    num_classes = y.shape[1]

                    # Cargar o crear modelo
                    cnn_modelo, _ = cargar_o_crear_modelo(
                        ruta_modelo=ruta_cnn_modelo,
                        input_shape=input_shape,
                        num_classes=num_classes,
                        datos_entrenamiento=(X, y))
            elif (dispositivo == 'CPU'):
                print("üü¢ CPU seleccionada")
                # Preparar datos para CNN
                X, y = preparar_datos_cnn(arr_norm, pix_prom_defo, pix_prom_veg)
                input_shape = (X.shape[1], 1)
                num_classes = y.shape[1]

                # Cargar o crear modelo
                cnn_modelo, _ = cargar_o_crear_modelo(
                    ruta_modelo=ruta_cnn_modelo,
                    input_shape=input_shape,
                    num_classes=num_classes,
                    datos_entrenamiento=(X, y))
        except Exception as e:
            print(f"‚ùå Error al manejar modelo CNN: {str(e)}")

if __name__ == "__main__":
    main()

